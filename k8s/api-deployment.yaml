apiVersion: apps/v1
kind: Deployment
metadata:
  name: churn-api
  namespace: churn-prediction
  labels:
    app: churn-api
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: churn-api
  template:
    metadata:
      labels:
        app: churn-api
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      # Add init container to verify model files exist
      initContainers:
      - name: check-model-files
        image: busybox
        command: ['sh', '-c']
        args:
          - |
            echo "Checking for model files..."
            if [ ! -d "/data/federated_data" ]; then
              echo "ERROR: /data/federated_data directory not found"
              exit 1
            fi
            if [ ! -d "/data/preprocessed_data" ]; then
              echo "ERROR: /data/preprocessed_data directory not found"
              exit 1
            fi
            if [ ! -f "/data/federated_data/federated_churn_model.h5" ]; then
              echo "ERROR: Model file not found at /data/federated_data/federated_churn_model.h5"
              echo "Available files in /data/federated_data:"
              ls -la /data/federated_data || true
              exit 1
            fi
            if [ ! -f "/data/preprocessed_data/preprocessor.pkl" ]; then
              echo "ERROR: Preprocessor file not found at /data/preprocessed_data/preprocessor.pkl"
              echo "Available files in /data/preprocessed_data:"
              ls -la /data/preprocessed_data || true
              exit 1
            fi
            echo "âœ“ All required model files found"
            echo "Model file size: $(du -h /data/federated_data/federated_churn_model.h5 | cut -f1)"
            echo "Preprocessor file size: $(du -h /data/preprocessed_data/preprocessor.pkl | cut -f1)"
        volumeMounts:
        - name: model-data
          mountPath: /data
      
      containers:
      - name: api
        image: churn-serving:latest  # Update with your image
        imagePullPolicy: Never
        ports:
        - containerPort: 8000
          name: http
          protocol: TCP
        env:
        - name: MODEL_PATH
          value: "/app/model_data/federated_data/federated_churn_model.h5"
        - name: PREPROCESSOR_PATH
          value: "/app/model_data/preprocessed_data/preprocessor.pkl"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        - name: LOG_LEVEL
          value: "INFO"
        volumeMounts:
        - name: model-data
          mountPath: /app/model_data
          readOnly: true
        
        # More lenient probes with longer startup time
        startupProbe:
          httpGet:
            path: /health
            port: 8000
          failureThreshold: 30
          periodSeconds: 10
          
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 20
          timeoutSeconds: 5
          failureThreshold: 3
          
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      
      volumes:
      - name: model-data
        persistentVolumeClaim:
          claimName: model-data-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: churn-api-service
  namespace: churn-prediction
  labels:
    app: churn-api
spec:
  selector:
    app: churn-api
  ports:
  - port: 8000
    targetPort: 8000
    name: http
    protocol: TCP
  type: LoadBalancer