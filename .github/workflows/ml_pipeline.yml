name: ML Pipeline CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 0'  # Weekly retraining on Sunday 2 AM
  workflow_dispatch:  # Allow manual triggers

env:
  PYTHON_VERSION: '3.10'
  MLFLOW_TRACKING_URI: 'http://localhost:5000'

jobs:
  # ============================================
  # JOB 1: Lint and Static Analysis
  # ============================================
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install linting tools
        run: |
          pip install flake8 black isort
      
      - name: Check code formatting with black
        run: black --check --diff . || true
        continue-on-error: true
      
      - name: Check imports with isort
        run: isort --check-only --diff . || true
        continue-on-error: true
      
      - name: Lint with flake8
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
        continue-on-error: true

  # ============================================
  # JOB 2: Unit Tests
  # ============================================
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-timeout
      
      - name: Run unit tests
        run: |
          pytest tests/ \
            --cov=. \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --timeout=300 \
            -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          fail_ci_if_error: false
      
      - name: Upload coverage report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: htmlcov/
        if: always()

  # ============================================
  # JOB 3: Data Preprocessing
  # ============================================
  preprocess:
    name: Preprocess Data
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Check for dataset
        run: |
          if [ ! -f "E_Commerce_Dataset.xlsx" ]; then
            echo "‚ö†Ô∏è  WARNING: Dataset file not found!"
            echo "Creating dummy dataset for CI purposes..."
            python3 << 'PYTHON_SCRIPT'
import pandas as pd
import numpy as np
np.random.seed(42)
n_samples = 1000
data = {
    'CustomerID': range(1, n_samples + 1),
    'Churn': np.random.randint(0, 2, n_samples),
    'Tenure': np.random.randint(0, 60, n_samples),
    'PreferredLoginDevice': np.random.choice(['Mobile Phone', 'Computer'], n_samples),
    'CityTier': np.random.randint(1, 4, n_samples),
    'WarehouseToHome': np.random.uniform(5, 50, n_samples),
    'PreferredPaymentMode': np.random.choice(['Credit Card', 'Debit Card', 'Cash on Delivery', 'UPI', 'E wallet'], n_samples),
    'Gender': np.random.choice(['Male', 'Female'], n_samples),
    'HourSpendOnApp': np.random.uniform(0, 10, n_samples),
    'NumberOfDeviceRegistered': np.random.randint(1, 6, n_samples),
    'PreferedOrderCat': np.random.choice(['Laptop & Accessory', 'Mobile Phone', 'Fashion', 'Grocery', 'Others'], n_samples),
    'SatisfactionScore': np.random.randint(1, 6, n_samples),
    'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),
    'NumberOfAddress': np.random.randint(1, 10, n_samples),
    'Complain': np.random.randint(0, 2, n_samples),
    'OrderAmountHikeFromlastYear': np.random.uniform(0, 50, n_samples),
    'CouponUsed': np.random.uniform(0, 10, n_samples),
    'OrderCount': np.random.uniform(1, 20, n_samples),
    'DaySinceLastOrder': np.random.uniform(0, 30, n_samples),
    'CashbackAmount': np.random.uniform(0, 500, n_samples),
}
df = pd.DataFrame(data)
df.to_excel('E_Commerce_Dataset.xlsx', sheet_name='E Comm', index=False)
print('‚úì Created dummy dataset')
PYTHON_SCRIPT
          fi
      
      - name: Preprocess data
        run: |
          python preprocess.py \
            --dataset E_Commerce_Dataset.xlsx \
            --clients 3 \
            --output-folder preprocessed_data
      
      - name: Verify preprocessing outputs
        run: |
          echo "Checking preprocessed files..."
          ls -lh preprocessed_data/
          
          if [ ! -f "preprocessed_data/preprocessor.pkl" ]; then
            echo "‚ùå ERROR: preprocessor.pkl not found"
            exit 1
          fi
          
          if [ ! -f "preprocessed_data/metadata.json" ]; then
            echo "‚ùå ERROR: metadata.json not found"
            exit 1
          fi
          
          echo "‚úì All preprocessing outputs found"
      
      - name: Upload preprocessed data
        uses: actions/upload-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
          retention-days: 7

  # ============================================
  # JOB 4: Model Training
  # ============================================
  train:
    name: Train Model
    runs-on: ubuntu-latest
    needs: preprocess
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-py${{ env.PYTHON_VERSION }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Download preprocessed data
        uses: actions/download-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
      
      - name: Check dataset
        run: |
          if [ ! -f "E_Commerce_Dataset.xlsx" ]; then
            echo "Creating dummy dataset..."
            python3 << 'PYTHON_SCRIPT'
import pandas as pd
import numpy as np
np.random.seed(42)
n_samples = 1000
data = {
    'CustomerID': range(1, n_samples + 1),
    'Churn': np.random.randint(0, 2, n_samples),
    'Tenure': np.random.randint(0, 60, n_samples),
    'PreferredLoginDevice': np.random.choice(['Mobile Phone', 'Computer'], n_samples),
    'CityTier': np.random.randint(1, 4, n_samples),
    'WarehouseToHome': np.random.uniform(5, 50, n_samples),
    'PreferredPaymentMode': np.random.choice(['Credit Card', 'Debit Card', 'Cash on Delivery', 'UPI', 'E wallet'], n_samples),
    'Gender': np.random.choice(['Male', 'Female'], n_samples),
    'HourSpendOnApp': np.random.uniform(0, 10, n_samples),
    'NumberOfDeviceRegistered': np.random.randint(1, 6, n_samples),
    'PreferedOrderCat': np.random.choice(['Laptop & Accessory', 'Mobile Phone', 'Fashion', 'Grocery', 'Others'], n_samples),
    'SatisfactionScore': np.random.randint(1, 6, n_samples),
    'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),
    'NumberOfAddress': np.random.randint(1, 10, n_samples),
    'Complain': np.random.randint(0, 2, n_samples),
    'OrderAmountHikeFromlastYear': np.random.uniform(0, 50, n_samples),
    'CouponUsed': np.random.uniform(0, 10, n_samples),
    'OrderCount': np.random.uniform(1, 20, n_samples),
    'DaySinceLastOrder': np.random.uniform(0, 30, n_samples),
    'CashbackAmount': np.random.uniform(0, 500, n_samples),
}
df = pd.DataFrame(data)
df.to_excel('E_Commerce_Dataset.xlsx', sheet_name='E Comm', index=False)
print('‚úì Created dummy dataset')
PYTHON_SCRIPT
          fi
      
      - name: Start MLflow server
        run: |
          echo "Starting MLflow tracking server..."
          mlflow server \
            --host 0.0.0.0 \
            --port 5000 \
            --backend-store-uri sqlite:///mlflow.db \
            --default-artifact-root ./mlruns &
          
          # Wait for MLflow to be ready
          timeout=60
          elapsed=0
          while ! curl -s http://localhost:5000/health > /dev/null; do
            sleep 2
            elapsed=$((elapsed + 2))
            if [ $elapsed -ge $timeout ]; then
              echo "‚ùå MLflow server failed to start"
              exit 1
            fi
            echo "Waiting for MLflow... ($elapsed/$timeout seconds)"
          done
          
          echo "‚úì MLflow server is ready"
      
      - name: Train federated model
        run: |
          python training_MLFlow.py \
            --dataset E_Commerce_Dataset.xlsx \
            --num-rounds 10 \
            --batch-size 8
        env:
          MLFLOW_TRACKING_URI: ${{ env.MLFLOW_TRACKING_URI }}
        timeout-minutes: 30
      
      - name: Evaluate model performance
        id: evaluate
        run: |
          python3 << 'PYTHON_SCRIPT'
import pandas as pd
import os
import sys

metrics_file = 'federated_data/round_evaluation/per_round_metrics.csv'

if not os.path.exists(metrics_file):
    print('‚ùå ERROR: Metrics file not found')
    sys.exit(1)

df = pd.read_csv(metrics_file)
final_metrics = df.iloc[-1]

print('='*60)
print('FINAL MODEL PERFORMANCE')
print('='*60)
print(f'Accuracy:  {final_metrics["eval_accuracy"]:.4f}')
print(f'Precision: {final_metrics["eval_precision"]:.4f}')
print(f'Recall:    {final_metrics["eval_recall"]:.4f}')
print(f'F1 Score:  {final_metrics["eval_f1"]:.4f}')
print(f'ROC AUC:   {final_metrics["eval_roc_auc"]:.4f}')
print('='*60)

MIN_ACCURACY = 0.70
if final_metrics['eval_accuracy'] < MIN_ACCURACY:
    print(f'‚ùå Model accuracy ({final_metrics["eval_accuracy"]:.4f}) below threshold ({MIN_ACCURACY})')
    sys.exit(1)
else:
    print(f'‚úì Model meets accuracy threshold ({MIN_ACCURACY})')

with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
    f.write(f'accuracy={final_metrics["eval_accuracy"]:.4f}\n')
    f.write(f'f1_score={final_metrics["eval_f1"]:.4f}\n')
PYTHON_SCRIPT
      
      - name: Create performance summary
        run: |
          echo "## üìä Model Training Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Accuracy** | ${{ steps.evaluate.outputs.accuracy }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **F1 Score** | ${{ steps.evaluate.outputs.f1_score }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Model training completed successfully!" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: trained-model
          path: |
            federated_data/federated_churn_model.h5
            federated_data/round_evaluation/
          retention-days: 30
      
      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v3
        with:
          name: mlflow-data
          path: |
            mlruns/
            mlflow.db
          retention-days: 7
        if: always()

  # ============================================
  # JOB 5: Build and Test Docker Image
  # ============================================
  docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: train
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: trained-model
          path: ./
      
      - name: Download preprocessed data
        uses: actions/download-artifact@v3
        with:
          name: preprocessed-data
          path: preprocessed_data/
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Build Docker image
        run: |
          docker build \
            -f Dockerfile.serving \
            -t churn-api:${{ github.sha }} \
            -t churn-api:latest \
            .
      
      - name: Test Docker image
        run: |
          echo "Starting container..."
          docker run -d \
            --name test-api \
            -p 8000:8000 \
            -e MODEL_PATH=/app/model_data/federated_data/federated_churn_model.h5 \
            -e PREPROCESSOR_PATH=/app/model_data/preprocessed_data/preprocessor.pkl \
            churn-api:latest
          
          # Wait for API to be ready
          timeout=60
          elapsed=0
          while ! curl -s http://localhost:8000/health > /dev/null; do
            sleep 2
            elapsed=$((elapsed + 2))
            if [ $elapsed -ge $timeout ]; then
              echo "‚ùå API failed to start"
              docker logs test-api
              exit 1
            fi
            echo "Waiting for API... ($elapsed/$timeout seconds)"
          done
          
          echo "‚úì API is running"
          
          # Health check
          echo "Running health check..."
          curl -f http://localhost:8000/health || exit 1
          
          # Test prediction
          echo "Testing prediction endpoint..."
          response=$(curl -s -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{
              "Tenure": 12.0,
              "PreferredLoginDevice": "Mobile Phone",
              "CityTier": 1,
              "WarehouseToHome": 15.0,
              "PreferredPaymentMode": "Credit Card",
              "Gender": "Male",
              "HourSpendOnApp": 3.0,
              "NumberOfDeviceRegistered": 3,
              "PreferedOrderCat": "Laptop & Accessory",
              "SatisfactionScore": 5,
              "MaritalStatus": "Single",
              "NumberOfAddress": 2,
              "Complain": 0,
              "OrderAmountHikeFromlastYear": 15.0,
              "CouponUsed": 1.0,
              "OrderCount": 5.0,
              "DaySinceLastOrder": 3.0,
              "CashbackAmount": 150.0
            }')
          
          echo "Response: $response"
          
          # Check if response contains expected fields
          if echo "$response" | grep -q "churn_probability"; then
            echo "‚úì Prediction endpoint working"
          else
            echo "‚ùå Prediction endpoint failed"
            exit 1
          fi
          
          # Cleanup
          docker stop test-api
          docker rm test-api
      
      - name: Save Docker image
        run: |
          docker save churn-api:latest | gzip > churn-api-latest.tar.gz
      
      - name: Upload Docker image
        uses: actions/upload-artifact@v3
        with:
          name: docker-image
          path: churn-api-latest.tar.gz
          retention-days: 7
      
      - name: Login to Docker Hub (if configured)
        if: github.event_name != 'pull_request' && secrets.DOCKER_USERNAME != ''
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
        continue-on-error: true
      
      - name: Push to Docker Hub (if configured)
        if: github.event_name != 'pull_request' && secrets.DOCKER_USERNAME != ''
        run: |
          docker tag churn-api:latest ${{ secrets.DOCKER_USERNAME }}/churn-api:${{ github.sha }}
          docker tag churn-api:latest ${{ secrets.DOCKER_USERNAME }}/churn-api:latest
          docker push ${{ secrets.DOCKER_USERNAME }}/churn-api:${{ github.sha }}
          docker push ${{ secrets.DOCKER_USERNAME }}/churn-api:latest
        continue-on-error: true

  # ============================================
  # JOB 6: Deploy (Placeholder)
  # ============================================
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: docker
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://your-deployment-url.com
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deployment placeholder
        run: |
          echo "==================================="
          echo "DEPLOYMENT CONFIGURATION"
          echo "==================================="
          echo ""
          echo "To enable production deployment:"
          echo ""
          echo "1. Set up Kubernetes cluster"
          echo "2. Configure kubectl credentials"
          echo "3. Add kubeconfig to GitHub Secrets"
          echo "4. Update this step with actual deployment commands"
          echo ""
          echo "Example deployment commands:"
          echo "  kubectl apply -f k8s/namespace.yaml"
          echo "  kubectl apply -f k8s/pvc.yaml"
          echo "  kubectl apply -f k8s/api-deployment.yaml"
          echo "  kubectl rollout status deployment/churn-api"
          echo ""
          echo "==================================="
      
      - name: Create deployment summary
        run: |
          echo "## üöÄ Deployment Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Pipeline completed successfully!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Model trained and evaluated" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Docker image built and tested" >> $GITHUB_STEP_SUMMARY
          echo "- ‚ÑπÔ∏è Deployment to production: Manual (placeholder)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. Review model performance metrics" >> $GITHUB_STEP_SUMMARY
          echo "2. Download Docker image artifact" >> $GITHUB_STEP_SUMMARY
          echo "3. Deploy to Kubernetes cluster manually" >> $GITHUB_STEP_SUMMARY
